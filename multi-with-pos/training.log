2021-06-14 18:30:10,609 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,611 Model: "Lemmatization(
  (embeddings): FlairEmbeddings(
    (lm): LanguageModel(
      (drop): Dropout(p=0.1, inplace=False)
      (encoder): Embedding(11854, 100)
      (rnn): LSTM(100, 2048)
      (decoder): Linear(in_features=2048, out_features=11854, bias=True)
    )
  )
  (embedding_dropout): Dropout(p=0.1, inplace=False)
  (encoder): GRU(2048, 128, num_layers=2, dropout=0.1, bidirectional=True)
  (decoder): GRU(2048, 128, num_layers=2, dropout=0.1)
  (concat): Linear(in_features=256, out_features=128, bias=True)
  (out): Linear(in_features=128, out_features=563, bias=True)
  (tag_embeddings): Embedding(2681, 2048)
)"
2021-06-14 18:30:10,612 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,613 Corpus: "MultiCorpus: 143270 train + 17339 dev + 16516 test sentences
 - UD_ENGLISH Corpus: 12543 train + 2001 dev + 2077 test sentences
 - UD_GERMAN Corpus: 13814 train + 799 dev + 977 test sentences
 - UD_FRENCH Corpus: 14449 train + 1476 dev + 416 test sentences
 - UD_SPANISH Corpus: 14187 train + 1400 dev + 426 test sentences
 - UD_HINDI Corpus: 13304 train + 1659 dev + 1684 test sentences
 - UD_CZECH Corpus: 68495 train + 9270 dev + 10148 test sentences
 - UD_SLOVENIAN Corpus: 6478 train + 734 dev + 788 test sentences"
2021-06-14 18:30:10,614 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,614 Parameters:
2021-06-14 18:30:10,616  - learning_rate: "0.05"
2021-06-14 18:30:10,617  - mini_batch_size: "32"
2021-06-14 18:30:10,617  - patience: "3"
2021-06-14 18:30:10,618  - anneal_factor: "0.5"
2021-06-14 18:30:10,618  - max_epochs: "2"
2021-06-14 18:30:10,619  - shuffle: "True"
2021-06-14 18:30:10,620  - train_with_dev: "False"
2021-06-14 18:30:10,620  - batch_growth_annealing: "False"
2021-06-14 18:30:10,621 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,621 Model training base path: "multi_with"
2021-06-14 18:30:10,622 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,623 Device: cuda:0
2021-06-14 18:30:10,623 ----------------------------------------------------------------------------------------------------
2021-06-14 18:30:10,624 Embeddings storage mode: cpu
2021-06-14 18:30:10,648 ----------------------------------------------------------------------------------------------------
2021-06-14 18:47:41,573 epoch 1 - iter 447/4478 - loss 2.81785886 - samples/sec: 13.61 - lr: 0.050000
2021-06-14 19:17:02,382 epoch 1 - iter 894/4478 - loss 1.73829665 - samples/sec: 8.12 - lr: 0.050000
2021-06-14 19:38:22,279 epoch 1 - iter 1341/4478 - loss 1.50324121 - samples/sec: 11.18 - lr: 0.050000
2021-06-14 20:01:13,675 epoch 1 - iter 1788/4478 - loss 1.41402426 - samples/sec: 10.43 - lr: 0.050000
2021-06-14 20:18:39,072 epoch 1 - iter 2235/4478 - loss 1.37113354 - samples/sec: 13.74 - lr: 0.050000
2021-06-14 20:37:18,053 epoch 1 - iter 2682/4478 - loss 1.20447583 - samples/sec: 13.01 - lr: 0.050000
2021-06-14 20:57:10,242 epoch 1 - iter 3129/4478 - loss 1.07375563 - samples/sec: 12.36 - lr: 0.050000
2021-06-14 21:15:11,415 epoch 1 - iter 3576/4478 - loss 0.97547354 - samples/sec: 13.49 - lr: 0.050000
2021-06-14 21:31:48,288 epoch 1 - iter 4023/4478 - loss 0.91139131 - samples/sec: 14.81 - lr: 0.050000
2021-06-14 21:49:04,776 epoch 1 - iter 4470/4478 - loss 0.87344522 - samples/sec: 13.96 - lr: 0.050000
2021-06-14 21:49:20,867 ----------------------------------------------------------------------------------------------------
2021-06-14 21:49:20,868 EPOCH 1 done: loss 0.8726 - lr 0.0500000
2021-06-14 22:24:50,965 DEV : loss 1.2009668350219727 - score 0.981
2021-06-14 22:25:24,676 BAD EPOCHS (no improvement): 0
2021-06-14 22:25:28,539 ----------------------------------------------------------------------------------------------------
2021-06-14 22:43:20,062 epoch 2 - iter 447/4478 - loss 0.95805603 - samples/sec: 13.46 - lr: 0.050000
2021-06-14 23:01:25,637 epoch 2 - iter 894/4478 - loss 0.84614315 - samples/sec: 13.44 - lr: 0.050000
2021-06-14 23:19:21,768 epoch 2 - iter 1341/4478 - loss 1.02483266 - samples/sec: 13.41 - lr: 0.050000
2021-06-14 23:37:14,028 epoch 2 - iter 1788/4478 - loss 0.98351352 - samples/sec: 13.46 - lr: 0.050000
2021-06-14 23:55:21,596 epoch 2 - iter 2235/4478 - loss 0.97085655 - samples/sec: 13.26 - lr: 0.050000
2021-06-15 00:13:18,462 epoch 2 - iter 2682/4478 - loss 0.95554684 - samples/sec: 13.55 - lr: 0.050000
2021-06-15 00:31:18,895 epoch 2 - iter 3129/4478 - loss 0.96672473 - samples/sec: 13.35 - lr: 0.050000
2021-06-15 00:49:14,393 epoch 2 - iter 3576/4478 - loss 0.95966739 - samples/sec: 13.41 - lr: 0.050000
2021-06-15 01:07:12,286 epoch 2 - iter 4023/4478 - loss 0.96284163 - samples/sec: 13.53 - lr: 0.050000
2021-06-15 01:25:19,176 epoch 2 - iter 4470/4478 - loss 0.95472683 - samples/sec: 13.27 - lr: 0.050000
2021-06-15 01:25:36,759 ----------------------------------------------------------------------------------------------------
2021-06-15 01:25:36,760 EPOCH 2 done: loss 0.9543 - lr 0.0500000
2021-06-15 02:01:11,140 DEV : loss 1.1166653633117676 - score 0.9844
2021-06-15 02:01:45,726 BAD EPOCHS (no improvement): 0
2021-06-15 02:01:53,424 ----------------------------------------------------------------------------------------------------
2021-06-15 02:01:53,425 Testing using best model ...
2021-06-15 02:01:53,426 loading file multi_with/best-model.pt
2021-06-15 02:34:13,548 0.9859	1.0000	0.9929
2021-06-15 02:34:13,549 
Results:
- Accuracy 0.9858692206122641

By class:

2021-06-15 02:34:13,549 ----------------------------------------------------------------------------------------------------
2021-06-15 02:34:13,550 ----------------------------------------------------------------------------------------------------
2021-06-15 02:39:34,755 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_english
2021-06-15 02:39:34,756 0.9859	1.0000	0.9929
2021-06-15 02:39:34,757 ----------------------------------------------------------------------------------------------------
2021-06-15 02:41:50,873 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_german
2021-06-15 02:41:50,874 0.9651	1.0000	0.9823
2021-06-15 02:41:50,875 ----------------------------------------------------------------------------------------------------
2021-06-15 02:43:01,519 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_french
2021-06-15 02:43:01,520 0.9732	1.0000	0.9864
2021-06-15 02:43:01,520 ----------------------------------------------------------------------------------------------------
2021-06-15 02:44:09,582 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_spanish
2021-06-15 02:44:09,583 0.9721	1.0000	0.9858
2021-06-15 02:44:09,584 ----------------------------------------------------------------------------------------------------
2021-06-15 02:47:11,465 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_hindi
2021-06-15 02:47:11,467 0.9654	1.0000	0.9824
2021-06-15 02:47:11,467 ----------------------------------------------------------------------------------------------------
2021-06-15 03:08:46,974 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_czech
2021-06-15 03:08:46,977 0.9935	1.0000	0.9967
2021-06-15 03:08:46,978 ----------------------------------------------------------------------------------------------------
2021-06-15 03:10:28,996 /vol/fob-vol7/mi19/chenlei/.flair/datasets/ud_slovenian
2021-06-15 03:10:28,997 0.9886	1.0000	0.9942
